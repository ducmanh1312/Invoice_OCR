{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Process txt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import cv2\n",
    "import re\n",
    "import glob\n",
    "\n",
    "def read_anotation(file_path):\n",
    "    annotations = []\n",
    "    with open(file_path, 'r', encoding=\"utf-8\") as lines:\n",
    "        for line in lines:\n",
    "            path = line.strip().split(\",\")\n",
    "            x1,y1,x2,y2,x3,y3,x4,y4,text = int(path[0]), int(path[1]), int(path[2]), int(path[3]),  int(path[4]), int(path[5]), int(path[6]), int(path[7]), path[8]\n",
    "            annotations.append([x1,y1,x3,y3,text])\n",
    "    return annotations\n",
    "\n",
    "def write_anotation(file, annotations, input_path, count):\n",
    "    for i,annotation in enumerate(annotations):\n",
    "        *_,text = annotation\n",
    "        new_input_path = input_path[:-4] + f\"_{i}.txt\"\n",
    "        line = f\"{new_input_path}\\t{text}\\n\"\n",
    "        file.write(line)\n",
    "    return count + i\n",
    "\n",
    "def img_crop(annotations, txt_path, new_dir):\n",
    "    img_path = txt_path[:-4] + f\".jpg\"\n",
    "    img_name = os.path.basename(txt_path).split(\".\")[0]\n",
    "    for i,annotation in enumerate(annotations):\n",
    "        new_img_path = new_dir + img_name + f\"_{i}.jpg\"\n",
    "        x1,y1,x3,y3,text = annotation\n",
    "        img = cv2.imread(img_path)\n",
    "        croped_img = img[y1:y3, x1:x3]\n",
    "        cv2.imwrite(new_img_path, croped_img)\n",
    "\n",
    "\n",
    "def preprocess(current_dir, new_dir, output_file):\n",
    "    with open (output_file, \"w\", encoding=\"utf-8\") as out_f:\n",
    "        count = 0\n",
    "        for txt_path in glob.glob(os.path.join(current_dir, \"*.txt\")):\n",
    "            img_path = txt_path[:-4] + f\".jpg\"\n",
    "            if \"(\" in txt_path or cv2.imread(img_path) is None:\n",
    "                print(f\"Ignore:{img_path}\")\n",
    "                continue\n",
    "            print(img_path)\n",
    "            annotations = read_anotation(txt_path)\n",
    "            count = write_anotation(out_f, annotations, txt_path, count)\n",
    "            img_crop(annotations, txt_path, new_dir)\n",
    "            print(count)\n",
    "\n",
    "current_dir = \"./invoice_ocr/img/\"\n",
    "new_dir = \"./invoice_ocr/img_crop/\"\n",
    "train_txt = \"./invoice_ocr/invoice_label_train.txt\"\n",
    "preprocess(current_dir, new_dir, train_txt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_txt(input_file, output_file, n_lines):\n",
    "    with open(input_file, 'r', encoding=\"utf-8\" ) as infile:\n",
    "        lines = infile.readlines()\n",
    "\n",
    "    with open(output_file, 'w', encoding=\"utf-8\") as outfile:\n",
    "        outfile.writelines(lines[:n_lines])\n",
    "    with open(input_file, 'w', encoding=\"utf-8\" ) as infile:\n",
    "        infile.writelines(lines[n_lines:])\n",
    "\n",
    "train_txt = \"./invoice_ocr/invoice_label_train.txt\"\n",
    "test_txt = \"./invoice_ocr/invoice_label_test.txt\"\n",
    "split_txt(train_txt,test_txt, 11000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "iot",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
